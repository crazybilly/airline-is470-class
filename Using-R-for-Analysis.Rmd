---
title: "Using R for Analysis"
output:
  slidy_presentation: default
  ioslides_presentation: default
---

## Jake Tolbert
### Director of Data Services
### Alumni & Development

## R & R Studio

- R - programming language with a focus on statistical analysis
- R Studio - an IDE for R

## Tool Comparison

![](tool-comparison-img.png)


## Complex Mailing Lists

Use R (or SQL or SAS or some such). 

- Data can change underneath, but criteria can be saved.
- QV has no way to do complex filtering eg:
    - T&D majors around Decatur OR $1000 lifetime gifts to T&D Building

## Pulling A List    
```{r echo=TRUE, eval = FALSE}

# imagine I'm connected to a database with databases:
#   - majors_tbl with pidm, major
#   - regions_tbl with pidm, region
#   - donors_tbl with pidm, td_gifts, athletics_gifts, uc_gifts, scholarship_gifts
#   - demographic_tbl with pidm, mailing address, and more ...

 
# get a list of all Theatre & Dance majors
tdmajors  <- majors_tbl %>% 
  filter( major == 'TD'  ) 

# get a list of everybody around Decatur
arounddecatur  <- regions_tbl %>% 
  filter( region == 'DECATUR' )

# get T&D majors around Decatur
td_around_decatur  <- tdmajors %>% 
  semi_join(arounddecatur, by = 'pidm') %>% 
  distinct(pidm)
```

## Pulling A List (cont.)

```{r echo=TRUE, eval = FALSE}
# get donors who've given $1000+ to Theatre & Dance building
td_donors  <- donors_tbl %>% 
  filter(td_gifts  >= 1000 ) %>% 
  distinct(pidm)

#combine both lists then add mailing data
my_mailing  <- bind_rows( td_around_decatur, td_donors) %>% 
  left_join( 
    demographic_tbl %>% 
        select(pidm, name, address, city, st, zip)
      , by = 'pidm', copy = T
  ) %>% 
  collect()
```


## Exploratory Analysis

- Use QV
  - load data
  - set up list boxes and charts
  - click around
- Use Excel
  - click around
  - run some pivot tables
- R requirees a mental model
  - use summary stats, environment pane
  - `View(airlinedata)`


## Statisical Analysis

Use R for complex statistical analysis.

```{r message=FALSE, warning=FALSE, include=FALSE}

knitr::opts_chunk$set(
    cache = T
  , highlight = T
)


library(tidyverse); library(lubridate); library(magrittr)
library(randomForest); library(caret); library(broom)

airlinedata  <- read_csv('data/airline_data_mco_2017.csv') %>% 
  mutate( 
      FL_DATE = ymd(FL_DATE) 
    , ORIGIN  = factor(ORIGIN)
    , UNIQUE_CARRIER = factor(UNIQUE_CARRIER)
    , DepTime    = ymd_hm(
                     paste(
                          FL_DATE
                        , sub("-.*", "", DEP_TIME_BLK )
                     ) 
                   )
  )


set.seed(500)
mydata  <- airlinedata %>% sample_n(5000) %>% 
  replace_na(list( ARR_DELAY = 0,    ARR_DELAY= 0))
  
```

## Quick Summary Data
```{r}
summary(airlinedata$DEP_DELAY)
```


## Quick Summary Data 
```{r}
hist(airlinedata$ARR_DELAY)
```

## Quick Summary Data 
```{r}
boxplot(airlinedata$ARR_DELAY ~ airlinedata$UNIQUE_CARRIER, ylim = c(-20,50))
```

## More Complex Analytical Tasks

```{r highlight = T}
cor.test(hour(airlinedata$DepTime), airlinedata$ARR_DELAY)
```

## More Complex Analytical Tasks
```{r highlight = T}
t.test(
    airlinedata %>% filter(ORIGIN == 'ORD') %>% pluck('ARR_DELAY')
  , airlinedata %>% filter(ORIGIN == 'CLT') %>% pluck('ARR_DELAY')
)
```



## Creating a Report for Others

1. Build with R Markdown 
    - integrate Markdown + R into generated html/pdf.
2. Use QV for dashboards, etc. 
3. Dump to Excel and format



## Building Statistical Models

```{r echo=T, message=FALSE, warning=FALSE, results = 'hide'}
lm_model <- lm(ARR_DELAY ~ DAY_OF_WEEK + DEP_DELAY, data = mydata)

rf_model <- randomForest(
                 x = mydata %>% select(DAY_OF_WEEK , UNIQUE_CARRIER)
               , y = mydata$ARR_DELAY 
             )

caret_model <- train(
                x = mydata %>% select(DAY_OF_WEEK , UNIQUE_CARRIER)
              , y = mydata$ARR_DELAY 
              , trControl = trainControl(number = 3)
              )
```

## Linear Model
```{r}
 tidy(lm_model)
```

## Random Forest Model
```{r}
print(rf_model)
```

## Caret Model
```{r}
print(caret_model)
```

## Build New Data to Predict New Cases

```{r}
newdata  <- data_frame(
    DAY_OF_WEEK      = c(1L,2L,3L,4L,5L)
  , UNIQUE_CARRIER  = factor(
                        c("AA", "AS", "EV", "WN", "OO")
                      , levels = levels(mydata$UNIQUE_CARRIER)
                    )
)

newdata
```

## Predict New Cases 
```{r}
predictions  <- predict(caret_model, newdata)
newdata$predictedDelay  <- predictions
newdata
```


## Use the Tidyverse
- a series of packages creating a new grammar for R
![](tidyverse.png)


## Load Packages in Every Script
My scripts almost always begin like this:

```{r echo = T, eval = FALSE, highlight = TRUE}
# libraries -------------------------------------------

library(tidyverse)
library(magrittr)
library(lubridate)
library(readxl)

# actual real work ------------------------------------------------

# start doing something here....

```


## Base R - Use Nested Functions

```{r echo=TRUE, eval = FALSE, highlight = TRUE}
fullstory  <- bop(
  scoop(
    hop(foo_foo, through = forest),
    up = field_mice
  ), 
  on = head
)
```
- really hard to read
- nobody thinks this way (so it's hard to write this way)

## Lots of Little Steps, Saving New Objects
```{r echo=TRUE, eval = FALSE, highlight = TRUE}
foo_foo_1 <- hop(  foo_foo  , through = forest)
foo_foo_2 <- scoop(foo_foo_1, up = field_mice)
fullstory <- bop(  foo_foo_2, on = head)
```

- not terrible
- but terribly messy


## Lots of Little Steps, Overwriting Each Time
```{r echo=TRUE, eval = FALSE, highlight = TRUE}
foo_foo   <- hop(  foo_foo, through = forest)
foo_foo   <- scoop(foo_foo, up = field_mice)
fullstory <- bop(  foo_foo, on = head)
```

- even better
- but debugging `scoop()` is a royal pain 

## Use the Pipe
```{r echo=TRUE, eval = FALSE, highlight = TRUE}
fullstory  <- foo_foo %>%
  hop(through = forest) %>%
  scoop(up = field_mouse) %>%
  bop(on = head)
```

- reads the way it happens
- not messy
- simple to debug 

## Dplyr's Verbs
```{r}

airlinedata %>% 
  mutate(
      DepTime    = as.numeric(str_remove(DEP_TIME_BLK, "-.*"))
    , DepMorning = ifelse(DepTime < 12, "morning", "evening")
  ) %>% 
  filter(ORIGIN == 'ORD' | ORIGIN == 'MIA') %>% 
  select(ORIGIN, DAY_OF_WEEK, FL_DATE, ARR_DELAY, DEP_DELAY, UNIQUE_CARRIER) %>% 
  arrange(DEP_DELAY)
```

## Pivot Table Verbs
```{r}
  airlinedata %>% 
  group_by(UNIQUE_CARRIER) %>% 
  summarize(
      n_flights    = n()
    , mean_delay   = mean(ARR_DELAY  , na.rm = T)
    , median_delay = median(ARR_DELAY, na.rm = T)
  )
```


## Fancy Plotting - Dates vs. Arrival Delay

```{r message =F, warning = F, error = F }
ggplot(mydata, aes(x = FL_DATE, y = ARR_DELAY)) + 
  geom_point(aes(color = UNIQUE_CARRIER)) + 
  geom_smooth() 
```

## Fancy Plotting - Dates vs. Arrival Delay

```{r message =F, warning = F, error = F }
ggplot(mydata, aes(x = FL_DATE, y =  ARR_DELAY)) + 
  geom_jitter(alpha = .5, aes(color = UNIQUE_CARRIER)) + 
  geom_smooth() + 
  coord_cartesian(ylim = c(0,100))
```


## Fancy Plotting-  Dates vs. Arrival Delay

```{r message =F, warning = F, error = F }
ggplot(mydata, aes(x = FL_DATE, y =   ARR_DELAY)) + 
  geom_jitter(alpha = .5, aes(color = UNIQUE_CARRIER)) + 
  geom_smooth() + 
  coord_cartesian(ylim = c(0,100)) + 
  facet_wrap(~UNIQUE_CARRIER)
```


## Lots More Code Examples on Github

- https://github.com/crazybilly/airline-is470-class
  - clone the repo to your desktop and open airline-project.Rproj
- documentation in Rmd/html files
- code examples in R files